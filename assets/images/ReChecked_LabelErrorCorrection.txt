# ───────────  PAPER METADATA  ───────────
title: "From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets"
#subtitle (optional): "a brief tagline"

authors:
  - name: "Sarina Penquitt"
    email or web-profile: "penquitt@uni-wuppertal.de"
    affiliations: [1,4]
  - name: "Jonathan Klees"
    email or web-profile: "klees@uni-wuppertal.de"
    affiliations: [1,4]
  - name: "Rinor Cakaj"
    email or web-profile: "rinor.cakaj@quality-match.com"
    affiliations: [3]
  - name: "Daniel Kondermann"
    email or web-profile: "dk@quality-match.com
    affiliations: [3]
  - name: "Matthias Rottmann"
    email or web-profile: "matthias.rottmann@uos.de"
    affiliations: [2]
  - name: "Lars Schmarje"
    email or web-profile: "lars.schmarje@quality-match.com"
    affiliations: [3]

affiliations:
  1: "Department of Mathematics, University of Wuppertal, Wuppertal, Germany"
  2: "Institute of Computer Science, Osnabrück University, Osnabrück, Germany"
  3: "Quality Match, Heidelberg, Germany"
  4: "Equal contribution"

publication (optional):
  #venue: "Conference or Journal Name, Year"
  arxiv_id: "2508.06556"
  date: "2025-08-06"

# ───────────  HERO BUTTONS  ───────────
  text: "arXiv Page"
  - url: "https://arxiv.org/abs/2508.06556"
  text: "GitHub Code"
  -  url: "https://github.com/JonathanKlees/rechecked"

# ───────────  HERO MEDIA (optional)  ───────────
  images: image from figure 1    # 1–4 images
  #video:                               # YouTube/other
  #  url: "https://www.youtube.com/watch?v=…"
  #interactive demo:       # e.g. Custom interactive demo

# ───────────  CONTENT SECTIONS  ───────────
# (You can add/remove or rename any of these entries—or define new ones!)

sections:

  - title: "Abstract"
    type: text
    content: "We introduce a semi-automated framework for label-error correction called REC✓D (Rechecked). Building on existing detectors, the framework pairs their error proposals with lightweight, 
              crowdsourced microtasks. These tasks enable multiple annotators to independently verify each candidate bounding box, and their responses are aggregated to estimate ambiguity and improve 
              label quality. To demonstrate the effectiveness of REC✓D, we apply it to the class pedestrian in the KITTI dataset. Our crowdsourced review yields high-quality corrected annotations, which 
              indicate a rate of at least 24% of missing and inaccurate annotations in original annotations. This validated set will be released as a new real-world benchmark for label error detection 
              and correction. We show that current label error detection methods, when combined with our correction framework, can recover hundreds of errors in the time it would take a human to annotate 
              bounding boxes from scratch. However, even the best methods still miss up to 66% of the true errors and with low quality labels introduce more errors than they find. This highlights the urgent 
              need for further research, now enabled by our released benchmark."
⠀
⠀
  - title: "Method Overview"
    type: mixed
    intro: "We propose a semi-automatic framework that combines label error detection methods with a microtask based review process to efficiently correct label errors. It consists of three main stages: object detection, label error proposal, and microtask based correction. "
    galleries:                         # one or more image galleries
      - image title: "Overview of our workflow REC(haken)D to detect and correct label errors in object detection datasets."
        images: image from figure 2                       # 1-4 images
      - image title: "Microtasks interface"
        images: image from figure 3                        # 1-4 images
    additional text:                   # optional list of steps
      - "**Step 1:** Object Detection Models"
            # short description of Step 1
            "A trained object detector is used to obtain predictions on the respective dataset. We use YOLOX and Cascade R-CNN and these detectors are trained sequentially, with the output of one detector 
             serving as the training set for the subsequent one."
      - "**Step 2:** Label Error Detection Methods"
            # short description of Step 2
            "Generating automatically proposals for label errors by integrating existing label error detection methods, including MetaDetect (Quelle einbauen?), loss-based instance-wise scoring (Quelle 
            einbauen?) and ObjectLab (Quelle einbauen?). Each method predicts a score that reflects the likelihood of a predicted box indicating a label error for every detected bounding box."
      - "**Step 3:** Error Correction"
            # short description of Step 3
            "The label error proposals are evaluated manually. We created short and easy-to-answer questions referred to as microtasks. With microtasks, annotators can quickly answer one simple question at a time We repeat the task with severaö people at the same time resulting in an estimate of the underlying distribution of the outcomes associated to this question. The microtask we used to construct the validated annotations of the KITTI dataset."
⠀
⠀
  - title: "Metrics at a Glance"
    type: mixed
    subsections:
      - title: "Number of identified label errors for the class pedestrian in the KITTI dataset."           # name of the explained metric 
        description: "The number of identified label errors depend on the probability threshold for soft label annotations and the minimal height of considered objects. Through comparison of original 
                     and validated annotations, we identify a number of label errors in the original dataset even when considering only evident errors."
        chart: table 3                        # single image or chart as LaTeX
      - title: "Validated GT probability vs. Human Perception"
        description: "Comparison of provided validated GT probability of being a pedestrian (y-axis). Each dot represents an annotation by three expert annotators and its corresponding probability in 
                    the validated GT. The diamond represents the center of the mean, the dashed lines the standard deviation and the star the median per annotator answer."
        chart: image of figure 4                         # single image or chart as LaTeX
⠀
⠀  
  - title: "Overlooked Objects in KITTI GT"
    type: mixed
    description: "Overlooked objects (in red color) that are not contained in original annotations (green color). These examples have a soft label probability of 0.8 or higher as well as a bounding box 
                    height of 40 pixels or more."
    media: Images of label_error_0, label_error_1, label_error_2, label_error_3 			        # any required media
    notes: 		        # any notes or ideas about the interactive section
⠀
⠀
 # - title: "Custom"
 #   type: custom
 #   description: "describe your custom section"
 #   media: 			        # any required media
 #   notes: 			        # any notes or ideas about the section

# ───────────  FOOTER SECTIONS  ───────────
  - title: "Resources & Links"
    type: links
    links:
      - text: "PDF"
        url: "https://arxiv.org/pdf/2508.06556"
      - text: "arXiv abstract & BibTeX"
        url: "https://arxiv.org/abs/2508.06556"
      - text: "Official implementation (PyTorch)"
        url: "https://github.com/JonathanKlees/rechecked"
⠀
⠀
  - title: "Acknowledgments"
    type: text
    content: |      # list project grants and special acknowledgements
    	"S.P. and M.R. acknowledge support by the German Federal Ministry of Education and Research (BMBF) within the junior research group project “UnrEAL” (grant no. 01IS22069). 
    	J.K. and M.R. acknowledge support by the German Federal Ministry of Education and Research (BMBF) within the project “RELiABEL” (grant no. 01IS24019B).
        R.C., D.K. and L.S. also acknowledge support within the project “RELiABEL” (grant no. 01IS24019A)."
    media: lab logo, aber Project Logo müssen wir später hinzufügen, wenn Jonathan wieder da ist, weil er hat das richtige Logo.			      # project and lab logos
⠀
⠀
  - title: "Citation"
    type: text
    bibtex: "@article{penquitt2025labelerrordetectioncorrection,
                title={From Label Error Detection to Correction: A Modular Framework and Benchmark for Object Detection Datasets}, 
                author={Penquitt, S. and Klees, J. and Cakaj, R. and Kondermann, D. and Rottmann, M. and Schmarje, L.},
                journal={arXiv:2508.06556},
                year={2025} 
              }"
⠀
⠀
  - title: "Contact"
    type: text
    contacts:
      - label: "Lead Author Email"
        value: "penquitt@uni-wuppertal.de"
      - label: "Open a ticket"
	value: "https://github.com/JonathanKlees/rechecked"
